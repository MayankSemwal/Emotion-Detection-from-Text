{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk \n",
    "from nltk import pos_tag_sents, word_tokenize, pos_tag\n",
    "from nltk import word_tokenize\n",
    "# Load Text Cleaning Pkgs\n",
    "# !pip install neattext\n",
    "# !pip install scikit-multilearn\n",
    "import neattext.functions as nfx\n",
    "import neattext as nt\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import LabelPowerset, ClassifierChain, BinaryRelevance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "STOPLIST = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Before cleaning: (20000, 10)\n",
      "Shape After cleaning: (19464, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>thankfulness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>guilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What can happen to you if your depressed #depr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@user I am for my family s complete lack of in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>jennifer reyna haha I know ! I was trying to c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@user Thanks for helping with @user They upgra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No stroller or baby dog headed to hike #freedom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  anger  fear  joy  love  \\\n",
       "0  What can happen to you if your depressed #depr...    0.0   0.0  0.0   0.0   \n",
       "1  @user I am for my family s complete lack of in...    0.0   0.0  0.0   0.0   \n",
       "2  jennifer reyna haha I know ! I was trying to c...    0.0   0.0  0.0   0.0   \n",
       "3  @user Thanks for helping with @user They upgra...    0.0   0.0  0.0   0.0   \n",
       "4    No stroller or baby dog headed to hike #freedom    0.0   0.0  0.0   0.0   \n",
       "\n",
       "   sadness  surprise  thankfulness  disgust  guilt  \n",
       "0      1.0       0.0           0.0      0.0    0.0  \n",
       "1      0.0       0.0           1.0      0.0    0.0  \n",
       "2      1.0       0.0           0.0      0.0    0.0  \n",
       "3      0.0       1.0           0.0      0.0    0.0  \n",
       "4      0.0       0.0           1.0      0.0    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"dataset1.csv\")\n",
    "print(\"Shape Before cleaning:\", df_train.shape)\n",
    "df_train.drop_duplicates(subset=['text'], inplace=True)\n",
    "df_train[pd.isnull(df_train).any(axis=1)]\n",
    "df_train = df_train.interpolate()  # Interpolate our data to get rid of null values\n",
    "print(\"Shape After cleaning:\", df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9\n",
    "df_train['text'] = df_train['text'].astype(str)\n",
    "y = df_train.iloc[: , -N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise in every text before cleaning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        {'text_noise': 8.080808080808081, 'text_length...\n",
       "1        {'text_noise': 12.162162162162163, 'text_lengt...\n",
       "2        {'text_noise': 11.11111111111111, 'text_length...\n",
       "3        {'text_noise': 11.904761904761903, 'text_lengt...\n",
       "4        {'text_noise': 6.382978723404255, 'text_length...\n",
       "                               ...                        \n",
       "19995    {'text_noise': 14.285714285714285, 'text_lengt...\n",
       "19996    {'text_noise': 9.803921568627452, 'text_length...\n",
       "19997    {'text_noise': 3.389830508474576, 'text_length...\n",
       "19998    {'text_noise': 4.615384615384616, 'text_length...\n",
       "19999    {'text_noise': 15.909090909090908, 'text_lengt...\n",
       "Name: text, Length: 19464, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Noise in every text before cleaning\")\n",
    "df_train['text'].apply(lambda x:nt.TextFrame(x).noise_scan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise after cleaning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        {'text_noise': 0, 'text_length': 66, 'noise_co...\n",
       "1        {'text_noise': 0, 'text_length': 47, 'noise_co...\n",
       "2        {'text_noise': 0, 'text_length': 76, 'noise_co...\n",
       "3        {'text_noise': 0, 'text_length': 37, 'noise_co...\n",
       "4        {'text_noise': 0, 'text_length': 38, 'noise_co...\n",
       "                               ...                        \n",
       "19995    {'text_noise': 0, 'text_length': 40, 'noise_co...\n",
       "19996    {'text_noise': 0, 'text_length': 20, 'noise_co...\n",
       "19997    {'text_noise': 0, 'text_length': 106, 'noise_c...\n",
       "19998    {'text_noise': 0, 'text_length': 40, 'noise_co...\n",
       "19999    {'text_noise': 0, 'text_length': 21, 'noise_co...\n",
       "Name: text, Length: 19464, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df_train['text'].apply(nfx.remove_stopwords)\n",
    "corpus = corpus.apply(nfx.remove_punctuations)\n",
    "corpus = corpus.apply(nfx.remove_userhandles)\n",
    "\n",
    "print (\"Noise after cleaning\")\n",
    "corpus.apply(lambda x:nt.TextFrame(x).noise_scan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "Xfeatures = tfidf.fit_transform(corpus).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xfeatures, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,mlb_estimator,xtrain,ytrain,xtest,ytest):\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    clf_predictions = clf.predict(xtest)\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    # Hamming loss to determine the fraction of incorrect predictions of a given model. \n",
    "    ham = hamming_loss(ytest,clf_predictions)  \n",
    "    result = {\"accuracy:\":acc, \"hamming_score\":ham}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier {'accuracy:': 0.5815068493150685, 'hamming_score': 0.10013318112633181}\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "\n",
    "# Multi-class classifier is trained on all the possible label combinations in our data\n",
    "mnb_model = build_model(MultinomialNB(), LabelPowerset, X_train, y_train, X_test, y_test)\n",
    "print(\"Multinomial Naive Bayes Classifier\", mnb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier {'accuracy:': 0.6217465753424658, 'hamming_score': 0.09084855403348555}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_model = build_model(RandomForestClassifier(n_estimators=9), LabelPowerset, X_train, y_train, X_test, y_test)\n",
    "print(\"Random Forest Classifier\", rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Classifier {'accuracy:': 0.649486301369863, 'hamming_score': 0.08310502283105023}\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "lg_model = build_model(LogisticRegression(solver='lbfgs', multi_class='multinomial', penalty='l2', C=1.0, max_iter=200), \n",
    "                        LabelPowerset, X_train, y_train, X_test, y_test)\n",
    "print(\"Logistic regression Classifier\", lg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Classifier {'accuracy:': 0.675513698630137, 'hamming_score': 0.0764269406392694}\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM classification\n",
    "\n",
    "svc_model = build_model(LinearSVC(tol=1e-05), LabelPowerset, X_train, y_train, X_test, y_test)\n",
    "print(\"Linear SVC Classifier\", svc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise' 'thankfulness' 'disgust'\n",
      " 'guilt']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Making a single prediction from dataset 1\n",
    "print(y.columns.values)\n",
    "for i in range(15):\n",
    "    ex1 = df_train['text'].iloc[i]\n",
    "    vec_example = tfidf.transform([ex1])\n",
    "    binary_rel_clf = BinaryRelevance(LinearSVC(tol=1e-05))\n",
    "    binary_rel_clf.fit(X_train,y_train)\n",
    "    output = binary_rel_clf.predict(vec_example).toarray()\n",
    "    print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a single prediction from dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('dataset2.csv', sep='\\t', names= ['text'])\n",
    "df_test.drop_duplicates(subset=['text'], inplace=True)\n",
    "corpus1 = df_test['text'].apply(nfx.remove_stopwords)\n",
    "corpus1 = corpus1.apply(nfx.remove_punctuations)\n",
    "corpus1 = corpus1.apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    ex1 = corpus1.iloc[i]\n",
    "    vec_example = tfidf.transform([ex1])\n",
    "    binary_rel_clf = BinaryRelevance(LinearSVC(tol=1e-05))\n",
    "    binary_rel_clf.fit(X_test,y_test)\n",
    "    print(binary_rel_clf.predict(vec_example).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
